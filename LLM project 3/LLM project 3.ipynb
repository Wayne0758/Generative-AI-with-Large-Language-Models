{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d7d1257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\wayne0758\\anaconda3\\envs\\pytorch\\lib\\site-packages (24.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py egg_info did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [7 lines of output]\n",
      "  Traceback (most recent call last):\n",
      "    File \"<string>\", line 2, in <module>\n",
      "    File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "    File \"C:\\Users\\Wayne0758\\AppData\\Local\\Temp\\pip-install-qkjqa_mh\\pef_706608e2425241b68f9401e8b9cb382f\\setup.py\", line 7, in <module>\n",
      "      readme = f.read()\n",
      "               ^^^^^^^^\n",
      "  UnicodeDecodeError: 'cp950' codec can't decode byte 0xe2 in position 535: illegal multibyte sequence\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "Encountered error while generating package metadata.\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/trl.git@7630f877f91c556d9e5a3baa4b6e2894d90ff84c\n",
      "  Cloning https://github.com/huggingface/trl.git (to revision 7630f877f91c556d9e5a3baa4b6e2894d90ff84c) to c:\\users\\wayne0758\\appdata\\local\\temp\\pip-req-build-zhtuokgb\n",
      "  Resolved https://github.com/huggingface/trl.git to commit 7630f877f91c556d9e5a3baa4b6e2894d90ff84c\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: torch>=1.4.0 in c:\\users\\wayne0758\\anaconda3\\envs\\pytorch\\lib\\site-packages (from trl==0.7.12.dev0) (2.2.1)\n",
      "Requirement already satisfied: transformers>=4.31.0 in c:\\users\\wayne0758\\anaconda3\\envs\\pytorch\\lib\\site-packages (from trl==0.7.12.dev0) (4.42.3)\n",
      "Requirement already satisfied: numpy>=1.18.2 in c:\\users\\wayne0758\\anaconda3\\envs\\pytorch\\lib\\site-packages (from trl==0.7.12.dev0) (1.26.4)\n",
      "Requirement already satisfied: accelerate in c:\\users\\wayne0758\\anaconda3\\envs\\pytorch\\lib\\site-packages (from trl==0.7.12.dev0) (0.31.0)\n",
      "Requirement already satisfied: datasets in c:\\users\\wayne0758\\anaconda3\\envs\\pytorch\\lib\\site-packages (from trl==0.7.12.dev0) (2.20.0)\n",
      "Requirement already satisfied: tyro>=0.5.11 in c:\\users\\wayne0758\\anaconda3\\envs\\pytorch\\lib\\site-packages (from trl==0.7.12.dev0) (0.8.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\wayne0758\\anaconda3\\envs\\pytorch\\lib\\site-packages (from torch>=1.4.0->trl==0.7.12.dev0) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\wayne0758\\anaconda3\\envs\\pytorch\\lib\\site-packages (from torch>=1.4.0->trl==0.7.12.dev0) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\wayne0758\\anaconda3\\envs\\pytorch\\lib\\site-packages (from torch>=1.4.0->trl==0.7.12.dev0) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\wayne0758\\anaconda3\\envs\\pytorch\\lib\\site-packages (from torch>=1.4.0->trl==0.7.12.dev0) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\wayne0758\\anaconda3\\envs\\pytorch\\lib\\site-packages (from torch>=1.4.0->trl==0.7.12.dev0) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\wayne0758\\anaconda3\\envs\\pytorch\\lib\\site-packages (from torch>=1.4.0->trl==0.7.12.dev0) (2024.2.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\wayne0758\\anaconda3\\envs\\pytorch\\lib\\site-packages (from transformers>=4.31.0->trl==0.7.12.dev0) (0.23.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\wayne0758\\anaconda3\\envs\\pytorch\\lib\\site-packages (from transformers>=4.31.0->trl==0.7.12.dev0) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\wayne0758\\anaconda3\\envs\\pytorch\\lib\\site-packages (from transformers>=4.31.0->trl==0.7.12.dev0) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\wayne0758\\anaconda3\\envs\\pytorch\\lib\\site-packages (from transformers>=4.31.0->trl==0.7.12.dev0) (2024.5.15)\n",
      "Requirement already satisfied: requests in c:\\users\\wayne0758\\anaconda3\\envs\\pytorch\\lib\\site-packages (from transformers>=4.31.0->trl==0.7.12.dev0) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\wayne0758\\anaconda3\\envs\\pytorch\\lib\\site-packages (from transformers>=4.31.0->trl==0.7.12.dev0) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\wayne0758\\anaconda3\\envs\\pytorch\\lib\\site-packages (from transformers>=4.31.0->trl==0.7.12.dev0) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\wayne0758\\anaconda3\\envs\\pytorch\\lib\\site-packages (from transformers>=4.31.0->trl==0.7.12.dev0) (4.66.4)\n",
      "Requirement already satisfied: docstring-parser>=0.16 in c:\\users\\wayne0758\\anaconda3\\envs\\pytorch\\lib\\site-packages (from tyro>=0.5.11->trl==0.7.12.dev0) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in c:\\users\\wayne0758\\anaconda3\\envs\\pytorch\\lib\\site-packages (from tyro>=0.5.11->trl==0.7.12.dev0) (13.7.1)\n",
      "Requirement already satisfied: shtab>=1.5.6 in c:\\users\\wayne0758\\anaconda3\\envs\\pytorch\\lib\\site-packages (from tyro>=0.5.11->trl==0.7.12.dev0) (1.7.1)\n",
      "Requirement already satisfied: colorama>=0.4.0 in c:\\users\\wayne0758\\anaconda3\\envs\\pytorch\\lib\\site-packages (from tyro>=0.5.11->trl==0.7.12.dev0) (0.4.6)\n",
      "Requirement already satisfied: psutil in c:\\users\\wayne0758\\anaconda3\\envs\\pytorch\\lib\\site-packages (from accelerate->trl==0.7.12.dev0) (5.9.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\wayne0758\\anaconda3\\envs\\pytorch\\lib\\site-packages (from datasets->trl==0.7.12.dev0) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\wayne0758\\anaconda3\\envs\\pytorch\\lib\\site-packages (from datasets->trl==0.7.12.dev0) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\wayne0758\\anaconda3\\envs\\pytorch\\lib\\site-packages (from datasets->trl==0.7.12.dev0) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\wayne0758\\anaconda3\\envs\\pytorch\\lib\\site-packages (from datasets->trl==0.7.12.dev0) (2.2.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\wayne0758\\anaconda3\\envs\\pytorch\\lib\\site-packages (from datasets->trl==0.7.12.dev0) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\wayne0758\\anaconda3\\envs\\pytorch\\lib\\site-packages (from datasets->trl==0.7.12.dev0) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\wayne0758\\anaconda3\\envs\\pytorch\\lib\\site-packages (from datasets->trl==0.7.12.dev0) (3.9.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\wayne0758\\anaconda3\\envs\\pytorch\\lib\\site-packages (from aiohttp->datasets->trl==0.7.12.dev0) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\wayne0758\\anaconda3\\envs\\pytorch\\lib\\site-packages (from aiohttp->datasets->trl==0.7.12.dev0) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\wayne0758\\anaconda3\\envs\\pytorch\\lib\\site-packages (from aiohttp->datasets->trl==0.7.12.dev0) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\wayne0758\\anaconda3\\envs\\pytorch\\lib\\site-packages (from aiohttp->datasets->trl==0.7.12.dev0) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\wayne0758\\anaconda3\\envs\\pytorch\\lib\\site-packages (from aiohttp->datasets->trl==0.7.12.dev0) (1.9.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\wayne0758\\anaconda3\\envs\\pytorch\\lib\\site-packages (from requests->transformers>=4.31.0->trl==0.7.12.dev0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\wayne0758\\anaconda3\\envs\\pytorch\\lib\\site-packages (from requests->transformers>=4.31.0->trl==0.7.12.dev0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\wayne0758\\anaconda3\\envs\\pytorch\\lib\\site-packages (from requests->transformers>=4.31.0->trl==0.7.12.dev0) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\wayne0758\\anaconda3\\envs\\pytorch\\lib\\site-packages (from requests->transformers>=4.31.0->trl==0.7.12.dev0) (2024.2.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\wayne0758\\anaconda3\\envs\\pytorch\\lib\\site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.7.12.dev0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\wayne0758\\anaconda3\\envs\\pytorch\\lib\\site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.7.12.dev0) (2.15.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\wayne0758\\anaconda3\\envs\\pytorch\\lib\\site-packages (from jinja2->torch>=1.4.0->trl==0.7.12.dev0) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\wayne0758\\anaconda3\\envs\\pytorch\\lib\\site-packages (from pandas->datasets->trl==0.7.12.dev0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\wayne0758\\anaconda3\\envs\\pytorch\\lib\\site-packages (from pandas->datasets->trl==0.7.12.dev0) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\wayne0758\\anaconda3\\envs\\pytorch\\lib\\site-packages (from pandas->datasets->trl==0.7.12.dev0) (2024.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\wayne0758\\anaconda3\\envs\\pytorch\\lib\\site-packages (from sympy->torch>=1.4.0->trl==0.7.12.dev0) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\wayne0758\\anaconda3\\envs\\pytorch\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.7.12.dev0) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\wayne0758\\anaconda3\\envs\\pytorch\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl==0.7.12.dev0) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/trl.git 'C:\\Users\\Wayne0758\\AppData\\Local\\Temp\\pip-req-build-zhtuokgb'\n",
      "  Running command git rev-parse -q --verify 'sha^7630f877f91c556d9e5a3baa4b6e2894d90ff84c'\n",
      "  Running command git fetch -q https://github.com/huggingface/trl.git 7630f877f91c556d9e5a3baa4b6e2894d90ff84c\n",
      "  Running command git checkout -q 7630f877f91c556d9e5a3baa4b6e2894d90ff84c\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install --disable-pip-version-check \\\n",
    "    torch \\\n",
    "    torchdata --quiet\n",
    "\n",
    "%pip install \\\n",
    "    transformers \\\n",
    "    datasets \\\n",
    "    evaluate \\\n",
    "    rouge_score \\\n",
    "    pef --quiet\n",
    "\n",
    "# Installing the Reinforcement Learning library directly from github.\n",
    "# I changed the tr1 library github website since top_k_top_p_filtering is not functioning well in the new transformers edition.\n",
    "%pip install git+https://github.com/huggingface/trl.git@7630f877f91c556d9e5a3baa4b6e2894d90ff84c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8946b83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wayne0758\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification, AutoModelForSeq2SeqLM, GenerationConfig\n",
    "from datasets import load_dataset\n",
    "from peft import PeftModel, PeftConfig, LoraConfig, TaskType\n",
    "\n",
    "# trl: Transformer Reinforcement Learning library\n",
    "from trl import PPOTrainer, PPOConfig, AutoModelForSeq2SeqLMWithValueHead\n",
    "from trl import create_reference_model\n",
    "from trl.core import LengthSampler\n",
    "\n",
    "import torch\n",
    "import evaluate\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# tqdm library makes the loops show a smart progress meter.\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9b5527f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 12460\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 1500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name=\"google/flan-t5-base\"\n",
    "huggingface_dataset_name = \"knkarthick/dialogsum\"\n",
    "\n",
    "dataset_original = load_dataset(huggingface_dataset_name)\n",
    "\n",
    "dataset_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad5e6605",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|███████████████████████████████████████████████████████████████| 10022/10022 [00:21<00:00, 462.76 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'dialogue', 'summary', 'topic', 'input_ids', 'query'],\n",
      "        num_rows: 8017\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'dialogue', 'summary', 'topic', 'input_ids', 'query'],\n",
      "        num_rows: 2005\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def build_dataset(model_name,\n",
    "                  dataset_name,\n",
    "                  input_min_text_length, \n",
    "                  input_max_text_length):\n",
    "\n",
    "    \"\"\"\n",
    "    Preprocess the dataset and split it into train and test parts.\n",
    "\n",
    "    Parameters:\n",
    "    - model_name (str): Tokenizer model name.\n",
    "    - dataset_name (str): Name of the dataset to load.\n",
    "    - input_min_text_length (int): Minimum length of the dialogues.\n",
    "    - input_max_text_length (int): Maximum length of the dialogues.\n",
    "        \n",
    "    Returns:\n",
    "    - dataset_splits (datasets.dataset_dict.DatasetDict): Preprocessed dataset containing train and test parts.\n",
    "    \"\"\"\n",
    "    \n",
    "    # load dataset (only \"train\" part will be enough for this lab).\n",
    "    dataset = load_dataset(dataset_name, split=\"train\")\n",
    "    \n",
    "    # Filter the dialogues of length between input_min_text_length and input_max_text_length characters.\n",
    "    dataset = dataset.filter(lambda x: len(x[\"dialogue\"]) > input_min_text_length and len(x[\"dialogue\"]) <= input_max_text_length, batched=False)\n",
    "\n",
    "    # Prepare tokenizer. Setting device_map=\"auto\" allows to switch between GPU and CPU automatically.\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    def tokenize(sample):\n",
    "        \n",
    "        # Wrap each dialogue with the instruction.\n",
    "        prompt = f\"\"\"\n",
    "Summarize the following conversation.\n",
    "\n",
    "{sample[\"dialogue\"]}\n",
    "\n",
    "Summary:\n",
    "\"\"\"\n",
    "        sample[\"input_ids\"] = tokenizer.encode(prompt)\n",
    "        \n",
    "        # This must be called \"query\", which is a requirement of our PPO library.\n",
    "        sample[\"query\"] = tokenizer.decode(sample[\"input_ids\"])\n",
    "        return sample\n",
    "\n",
    "    # Tokenize each dialogue.\n",
    "    dataset = dataset.map(tokenize, batched=False)\n",
    "    dataset.set_format(type=\"torch\")\n",
    "    \n",
    "    # Split the dataset into train and test parts.\n",
    "    dataset_splits = dataset.train_test_split(test_size=0.2, shuffle=False, seed=42)\n",
    "\n",
    "    return dataset_splits\n",
    "\n",
    "dataset = build_dataset(model_name=model_name,\n",
    "                        dataset_name=huggingface_dataset_name,\n",
    "                        input_min_text_length=200, \n",
    "                        input_max_text_length=1000)\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dcb0ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I download peft model from library instead of AWS\n",
    "peft_model_name='intotheverse/peft-dialogue-summary-checkpoint'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac6442c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_number_of_trainable_model_parameters(model):\n",
    "    trainable_model_params = 0\n",
    "    all_model_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_model_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_model_params += param.numel()\n",
    "    return f\"\\ntrainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b7cadb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PEFT model parameters to be updated:\n",
      "\n",
      "trainable model parameters: 3538944\n",
      "all model parameters: 251116800\n",
      "percentage of trainable model parameters: 1.41%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add the adapter to the original FLAN-T5 model.\n",
    "lora_config = LoraConfig(\n",
    "    r=32, # Rank\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q\", \"v\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM # FLAN-T5\n",
    ")\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name, \n",
    "                                              torch_dtype=torch.bfloat16)\n",
    "\n",
    "peft_model = PeftModel.from_pretrained(model, \n",
    "                                       peft_model_name, \n",
    "                                       lora_config=lora_config,\n",
    "                                       torch_dtype=torch.bfloat16,\n",
    "                                       is_trainable=True)\n",
    "\n",
    "print(f'PEFT model parameters to be updated:\\n{print_number_of_trainable_model_parameters(peft_model)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cfc0138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPO model parameters to be updated (ValueHead + 769 params):\n",
      "\n",
      "trainable model parameters: 3539713\n",
      "all model parameters: 251117569\n",
      "percentage of trainable model parameters: 1.41%\n",
      "\n",
      "ValueHead(\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (summary): Linear(in_features=768, out_features=1, bias=True)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# the Proximal Policy Optimization (PPO) model\n",
    "ppo_model = AutoModelForSeq2SeqLMWithValueHead.from_pretrained(peft_model,                                                               \n",
    "                                                               torch_dtype=torch.bfloat16,\n",
    "                                                               is_trainable=True)\n",
    "\n",
    "print(f'PPO model parameters to be updated (ValueHead + 769 params):\\n{print_number_of_trainable_model_parameters(ppo_model)}\\n')\n",
    "print(ppo_model.v_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13af324c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference model parameters to be updated:\n",
      "\n",
      "trainable model parameters: 0\n",
      "all model parameters: 251117569\n",
      "percentage of trainable model parameters: 0.00%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# a frozen copy of the PPO which will not be fine-tuned - a reference model.\n",
    "ref_model = create_reference_model(ppo_model)\n",
    "\n",
    "print(f'Reference model parameters to be updated:\\n{print_number_of_trainable_model_parameters(ref_model)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa01d220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'nothate', 1: 'hate'}\n"
     ]
    }
   ],
   "source": [
    "# use Meta AI's RoBERTa-based hate speech model for the reward model.\n",
    "# This model will output logits and then predict probabilities across two classes: nothate and hate.\n",
    "toxicity_model_name = \"facebook/roberta-hate-speech-dynabench-r4-target\"\n",
    "toxicity_tokenizer = AutoTokenizer.from_pretrained(toxicity_model_name)\n",
    "toxicity_model = AutoModelForSequenceClassification.from_pretrained(toxicity_model_name)\n",
    "print(toxicity_model.config.id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aca9993e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits [not hate, hate]: [3.114102363586426, -2.489619016647339]\n",
      "probabilities [not hate, hate]: [0.9963293671607971, 0.0036706042010337114]\n",
      "reward (high): [3.114102363586426]\n"
     ]
    }
   ],
   "source": [
    "# Take a non-toxic text as an example\n",
    "non_toxic_text = \"#Person 1# tells Tommy that he didn't like the movie.\"\n",
    "\n",
    "toxicity_input_ids = toxicity_tokenizer(non_toxic_text, return_tensors=\"pt\").input_ids.to('cuda') # PC user has to add (.to('cuda'))\n",
    "toxicity_model.to('cuda')\n",
    "logits = toxicity_model(input_ids=toxicity_input_ids).logits\n",
    "print(f'logits [not hate, hate]: {logits.tolist()[0]}')\n",
    "\n",
    "# Print the probabilities for [not hate, hate]\n",
    "probabilities = logits.softmax(dim=-1).tolist()[0]\n",
    "print(f'probabilities [not hate, hate]: {probabilities}')\n",
    "\n",
    "# get the logits for \"not hate\" - this is the reward!\n",
    "not_hate_index = 0\n",
    "nothate_reward = (logits[:, not_hate_index]).tolist()\n",
    "print(f'reward (high): {nothate_reward}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6cbe02e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits [not hate, hate]: [-0.692115306854248, 0.37226971983909607]\n",
      "probabilities [not hate, hate]: [0.25647231936454773, 0.7435276508331299]\n",
      "reward (low): [-0.692115306854248]\n"
     ]
    }
   ],
   "source": [
    "# Take a toxic text as an example\n",
    "toxic_text = \"#Person 1# tells Tommy that the movie was terrible, dumb and stupid.\"\n",
    "\n",
    "toxicity_input_ids = toxicity_tokenizer(toxic_text, return_tensors=\"pt\").input_ids.to('cuda') # PC user has to add (.to('cuda'))\n",
    "\n",
    "logits = toxicity_model(toxicity_input_ids).logits\n",
    "print(f'logits [not hate, hate]: {logits.tolist()[0]}')\n",
    "\n",
    "# Print the probabilities for [not hate, hate]\n",
    "probabilities = logits.softmax(dim=-1).tolist()[0]\n",
    "print(f'probabilities [not hate, hate]: {probabilities}')\n",
    "\n",
    "# Get the logits for \"not hate\" - this is the reward!\n",
    "nothate_reward = (logits[:, not_hate_index]).tolist() \n",
    "print(f'reward (low): {nothate_reward}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8345413d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward model output:\n",
      "For non-toxic text\n",
      "[{'label': 'nothate', 'score': 3.114102363586426}, {'label': 'hate', 'score': -2.489619016647339}]\n",
      "[{'label': 'nothate', 'score': 0.9963293671607971}, {'label': 'hate', 'score': 0.0036706042010337114}]\n",
      "For toxic text\n",
      "[{'label': 'hate', 'score': 0.37226971983909607}, {'label': 'nothate', 'score': -0.692115306854248}]\n",
      "[{'label': 'hate', 'score': 0.7435276508331299}, {'label': 'nothate', 'score': 0.2564723491668701}]\n"
     ]
    }
   ],
   "source": [
    "device = 0 if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "sentiment_pipe = pipeline(\"sentiment-analysis\", \n",
    "                          model=toxicity_model_name, \n",
    "                          device=device)\n",
    "reward_logits_kwargs = {\n",
    "    \"top_k\": None, # Return all scores.\n",
    "    \"function_to_apply\": \"none\", # Set to \"none\" to retrieve raw logits.\n",
    "    \"batch_size\": 16\n",
    "}\n",
    "\n",
    "reward_probabilities_kwargs = {\n",
    "    \"top_k\": None, # Return all scores.\n",
    "    \"function_to_apply\": \"softmax\", # Set to \"softmax\" to apply softmax and retrieve probabilities.\n",
    "    \"batch_size\": 16\n",
    "}\n",
    "\n",
    "print(\"Reward model output:\")\n",
    "print(\"For non-toxic text\")\n",
    "print(sentiment_pipe(non_toxic_text, **reward_logits_kwargs))\n",
    "print(sentiment_pipe(non_toxic_text, **reward_probabilities_kwargs))\n",
    "print(\"For toxic text\")\n",
    "print(sentiment_pipe(toxic_text, **reward_logits_kwargs))\n",
    "print(sentiment_pipe(toxic_text, **reward_probabilities_kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6314043c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'nothate', 'score': 3.114102363586426}, {'label': 'hate', 'score': -2.489619016647339}]\n",
      "[{'label': 'nothate', 'score': 0.9963293671607971}, {'label': 'hate', 'score': 0.0036706042010337114}]\n"
     ]
    }
   ],
   "source": [
    "# PPO will be using logits only of the nothate class as the positive reward signal used to help detoxify the LLM outputs.\n",
    "print(sentiment_pipe(non_toxic_text, **reward_logits_kwargs))\n",
    "print(sentiment_pipe(non_toxic_text, **reward_probabilities_kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c4815f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'hate', 'score': 0.37226971983909607}, {'label': 'nothate', 'score': -0.692115306854248}]\n",
      "[{'label': 'hate', 'score': 0.7435276508331299}, {'label': 'nothate', 'score': 0.2564723491668701}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(sentiment_pipe(toxic_text, **reward_logits_kwargs))\n",
    "print(sentiment_pipe(toxic_text, **reward_probabilities_kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f04cb27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Toxicity\n",
    "toxicity_evaluator = evaluate.load(\"toxicity\", \n",
    "                                    toxicity_model_name,\n",
    "                                    module_type=\"measurement\",\n",
    "                                    toxic_label=\"hate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "739f2956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toxicity score for non-toxic text:\n",
      "[0.003670611185953021]\n",
      "\n",
      "Toxicity score for toxic text:\n",
      "[0.7435290813446045]\n"
     ]
    }
   ],
   "source": [
    "toxicity_score = toxicity_evaluator.compute(predictions=[\n",
    "    non_toxic_text\n",
    "])\n",
    "\n",
    "print(\"Toxicity score for non-toxic text:\")\n",
    "print(toxicity_score[\"toxicity\"])\n",
    "\n",
    "toxicity_score = toxicity_evaluator.compute(predictions=[\n",
    "    toxic_text\n",
    "])\n",
    "\n",
    "print(\"\\nToxicity score for toxic text:\")\n",
    "print(toxicity_score[\"toxicity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00a97140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_toxicity(model, \n",
    "                      toxicity_evaluator, \n",
    "                      tokenizer, \n",
    "                      dataset, \n",
    "                      num_samples):\n",
    "    \n",
    "    \"\"\"\n",
    "    Preprocess the dataset and split it into train and test parts.\n",
    "\n",
    "    Parameters:\n",
    "    - model (trl model): Model to be evaluated.\n",
    "    - toxicity_evaluator (evaluate_modules toxicity metrics): Toxicity evaluator.\n",
    "    - tokenizer (transformers tokenizer): Tokenizer to be used.\n",
    "    - dataset (dataset): Input dataset for the evaluation.\n",
    "    - num_samples (int): Maximum number of samples for the evaluation.\n",
    "        \n",
    "    Returns:\n",
    "    tuple: A tuple containing two numpy.float64 values:\n",
    "    - mean (numpy.float64): Mean of the samples toxicity.\n",
    "    - std (numpy.float64): Standard deviation of the samples toxicity.\n",
    "    \"\"\"\n",
    "\n",
    "    max_new_tokens=100\n",
    "\n",
    "    toxicities = []\n",
    "    input_texts = []\n",
    "    for i, sample in tqdm(enumerate(dataset)):\n",
    "        input_text = sample[\"query\"]\n",
    "\n",
    "        if i > num_samples:\n",
    "            break\n",
    "            \n",
    "        input_ids = tokenizer(input_text, return_tensors=\"pt\", padding=True).input_ids.to('cuda') # PC user has to add (.to('cuda'))\n",
    "        \n",
    "        generation_config = GenerationConfig(max_new_tokens=max_new_tokens,\n",
    "                                             tok_k=0.0,\n",
    "                                             top_p=1.0,\n",
    "                                             do_sample=True)\n",
    "\n",
    "        response_token_ids = model.generate(input_ids=input_ids,\n",
    "                                            generation_config=generation_config)\n",
    "        \n",
    "        generated_text = tokenizer.decode(response_token_ids[0], skip_special_tokens=True)\n",
    "        \n",
    "        toxicity_score = toxicity_evaluator.compute(predictions=[(input_text + \" \" + generated_text)])\n",
    "\n",
    "        toxicities.extend(toxicity_score[\"toxicity\"])\n",
    "\n",
    "    # Compute mean & std using np.\n",
    "    mean = np.mean(toxicities)\n",
    "    std = np.std(toxicities)\n",
    "        \n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "966c6898",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:19,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxicity [mean, std] before detox: [0.037318359811747956, 0.052221229799766206]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "ref_model.to('cuda') # this line is for PC user\n",
    "mean_before_detoxification, std_before_detoxification = evaluate_toxicity(model=ref_model, \n",
    "                                                                          toxicity_evaluator=toxicity_evaluator, \n",
    "                                                                          tokenizer=tokenizer, \n",
    "                                                                          dataset=dataset[\"test\"], \n",
    "                                                                          num_samples=10)\n",
    "\n",
    "print(f'toxicity [mean, std] before detox: [{mean_before_detoxification}, {std_before_detoxification}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c10b1747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collator input: [{'key1': 'value1', 'key2': 'value2', 'key3': 'value3'}]\n",
      "Collator output: {'key1': ['value1'], 'key2': ['value2'], 'key3': ['value3']}\n"
     ]
    }
   ],
   "source": [
    "# Initialize PPOTrainer\n",
    "def collator(data):\n",
    "    return dict((key, [d[key] for d in data]) for key in data[0])\n",
    "\n",
    "test_data = [{\"key1\": \"value1\", \"key2\": \"value2\", \"key3\": \"value3\"}]\n",
    "print(f'Collator input: {test_data}')\n",
    "print(f'Collator output: {collator(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e11f0468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the configuration parameters.\n",
    "learning_rate=1.41e-5\n",
    "max_ppo_epochs=1\n",
    "mini_batch_size=4\n",
    "batch_size=16\n",
    "\n",
    "config = PPOConfig(\n",
    "    model_name=model_name,    \n",
    "    learning_rate=learning_rate,\n",
    "    ppo_epochs=max_ppo_epochs,\n",
    "    mini_batch_size=mini_batch_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "ppo_trainer = PPOTrainer(config=config, \n",
    "                         model=ppo_model, \n",
    "                         ref_model=ref_model, \n",
    "                         tokenizer=tokenizer, \n",
    "                         dataset=dataset[\"train\"], \n",
    "                         data_collator=collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66065809",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:39, 39.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 32.757999420166016\n",
      "ppo/returns/mean: -0.6796975135803223\n",
      "ppo/policy/advantages_mean: -0.0013237111270427704\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [01:21, 40.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 32.313697814941406\n",
      "ppo/returns/mean: -0.6003026366233826\n",
      "ppo/policy/advantages_mean: 0.004295060411095619\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "3it [01:55, 37.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 23.12684440612793\n",
      "ppo/returns/mean: -0.3850144147872925\n",
      "ppo/policy/advantages_mean: 0.031370609998703\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [02:29, 36.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 25.694435119628906\n",
      "ppo/returns/mean: -0.2610011696815491\n",
      "ppo/policy/advantages_mean: 0.021239109337329865\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [03:04, 35.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 26.29637908935547\n",
      "ppo/returns/mean: -0.3571302592754364\n",
      "ppo/policy/advantages_mean: 0.01403020042926073\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [03:46, 37.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 30.35460090637207\n",
      "ppo/returns/mean: -0.41903096437454224\n",
      "ppo/policy/advantages_mean: 0.029968298971652985\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [04:28, 39.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 26.79494857788086\n",
      "ppo/returns/mean: -0.36164823174476624\n",
      "ppo/policy/advantages_mean: 0.024939969182014465\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [05:04, 38.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 28.664020538330078\n",
      "ppo/returns/mean: -0.4544193148612976\n",
      "ppo/policy/advantages_mean: 0.006451183930039406\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [05:47, 39.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 34.156455993652344\n",
      "ppo/returns/mean: -0.7025390863418579\n",
      "ppo/policy/advantages_mean: 0.028409339487552643\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [06:20, 38.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl: 26.74374008178711\n",
      "ppo/returns/mean: -0.4234893321990967\n",
      "ppo/policy/advantages_mean: 0.007610686123371124\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Fine-Tune the Model\n",
    "output_min_length = 100\n",
    "output_max_length = 400\n",
    "output_length_sampler = LengthSampler(output_min_length, output_max_length)\n",
    "\n",
    "generation_kwargs = {\n",
    "    \"min_length\": 5,\n",
    "    \"top_k\": 0.0,\n",
    "    \"top_p\": 1.0,\n",
    "    \"do_sample\": True\n",
    "}\n",
    "\n",
    "reward_kwargs = {\n",
    "    \"top_k\": None, # Return all scores.\n",
    "    \"function_to_apply\": \"none\", # You want the raw logits without softmax.\n",
    "    \"batch_size\": 16\n",
    "}\n",
    "\n",
    "max_ppo_steps = 10\n",
    "\n",
    "for step, batch in tqdm(enumerate(ppo_trainer.dataloader)):\n",
    "    # Break when you reach max_steps.\n",
    "    if step >= max_ppo_steps:\n",
    "        break   \n",
    "\n",
    "    prompt_tensors = batch[\"input_ids\"]\n",
    "\n",
    "    # Get response from FLAN-T5/PEFT LLM.\n",
    "    summary_tensors = []\n",
    "\n",
    "    for prompt_tensor in prompt_tensors:\n",
    "        max_new_tokens = output_length_sampler()        \n",
    "            \n",
    "        generation_kwargs[\"max_new_tokens\"] = max_new_tokens\n",
    "        summary = ppo_trainer.generate(prompt_tensor, **generation_kwargs)\n",
    "        \n",
    "        summary_tensors.append(summary.squeeze()[-max_new_tokens:])\n",
    "        \n",
    "    # This needs to be called \"response\".\n",
    "    batch[\"response\"] = [tokenizer.decode(r.squeeze()) for r in summary_tensors]\n",
    "\n",
    "    # Compute reward outputs.\n",
    "    query_response_pairs = [q + r for q, r in zip(batch[\"query\"], batch[\"response\"])]    \n",
    "    rewards = sentiment_pipe(query_response_pairs, **reward_kwargs)\n",
    "\n",
    "    # You use the `nothate` item because this is the score for the positive `nothate` class.\n",
    "    reward_tensors = [torch.tensor(reward[not_hate_index][\"score\"]) for reward in rewards]    \n",
    "\n",
    "    # Run PPO step.\n",
    "    stats = ppo_trainer.step(prompt_tensors, summary_tensors, reward_tensors)\n",
    "    ppo_trainer.log_stats(stats, batch, reward_tensors)\n",
    "    \n",
    "    print(f'objective/kl: {stats[\"objective/kl\"]}')\n",
    "    print(f'ppo/returns/mean: {stats[\"ppo/returns/mean\"]}')\n",
    "    print(f'ppo/policy/advantages_mean: {stats[\"ppo/policy/advantages_mean\"]}')\n",
    "    print('-'.join('' for x in range(100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31808566",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:22,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxicity [mean, std] after detox: [0.022553021543320607, 0.03857762610589224]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Model Quantitatively\n",
    "ppo_model.to('cuda') # this line is for PC user\n",
    "mean_after_detoxification, std_after_detoxification = evaluate_toxicity(model=ppo_model, \n",
    "                                                                        toxicity_evaluator=toxicity_evaluator, \n",
    "                                                                        tokenizer=tokenizer, \n",
    "                                                                        dataset=dataset[\"test\"], \n",
    "                                                                        num_samples=10)\n",
    "print(f'toxicity [mean, std] after detox: [{mean_after_detoxification}, {std_after_detoxification}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b0ca9da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage improvement of toxicity score after detoxification:\n",
      "mean: 39.57%\n",
      "std: 26.13%\n"
     ]
    }
   ],
   "source": [
    "# Comparison the toxicity scores of the reference model and fine-tuned model\n",
    "mean_improvement = (mean_before_detoxification - mean_after_detoxification) / mean_before_detoxification\n",
    "std_improvement = (std_before_detoxification - std_after_detoxification) / std_before_detoxification\n",
    "\n",
    "print(f'Percentage improvement of toxicity score after detoxification:')\n",
    "print(f'mean: {mean_improvement*100:.2f}%')\n",
    "print(f'std: {std_improvement*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e010e449",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [01:25<00:00,  4.26s/it]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20\n",
    "compare_results = {}\n",
    "\n",
    "df_batch = dataset[\"test\"][0:batch_size]\n",
    "\n",
    "compare_results[\"query\"] = df_batch[\"query\"]\n",
    "prompt_tensors = df_batch[\"input_ids\"]\n",
    "\n",
    "summary_tensors_ref = []\n",
    "summary_tensors = []\n",
    "\n",
    "# Get response from ppo and base model.\n",
    "for i in tqdm(range(batch_size)):\n",
    "    gen_len = output_length_sampler()\n",
    "    generation_kwargs[\"max_new_tokens\"] = gen_len\n",
    "    \n",
    "    summary = ref_model.generate(\n",
    "        input_ids=torch.as_tensor(prompt_tensors[i]).unsqueeze(dim=0).to(device), \n",
    "        **generation_kwargs\n",
    "    ).squeeze()[-gen_len:]\n",
    "    summary_tensors_ref.append(summary)\n",
    "\n",
    "    summary = ppo_model.generate(\n",
    "        input_ids=torch.as_tensor(prompt_tensors[i]).unsqueeze(dim=0).to(device), \n",
    "        **generation_kwargs\n",
    "    ).squeeze()[-gen_len:]\n",
    "    summary_tensors.append(summary)\n",
    "\n",
    "# Decode responses.\n",
    "compare_results[\"response_before\"] = [tokenizer.decode(summary_tensors_ref[i]) for i in range(batch_size)]\n",
    "compare_results[\"response_after\"] = [tokenizer.decode(summary_tensors[i]) for i in range(batch_size)]\n",
    "\n",
    "# Sentiment analysis of query/response pairs before/after.\n",
    "texts_before = [d + s for d, s in zip(compare_results[\"query\"], compare_results[\"response_before\"])]\n",
    "rewards_before = sentiment_pipe(texts_before, **reward_kwargs)\n",
    "compare_results[\"reward_before\"] = [reward[not_hate_index][\"score\"] for reward in rewards_before]\n",
    "\n",
    "texts_after = [d + s for d, s in zip(compare_results[\"query\"], compare_results[\"response_after\"])]\n",
    "rewards_after = sentiment_pipe(texts_after, **reward_kwargs)\n",
    "compare_results[\"reward_after\"] = [reward[not_hate_index][\"score\"] for reward in rewards_after]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "787108bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>response_before</th>\n",
       "      <th>response_after</th>\n",
       "      <th>reward_before</th>\n",
       "      <th>reward_after</th>\n",
       "      <th>reward_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Today more and more families have personal computers. People have wider range of choice to communicate with the outside world. #Person2#: Right. With the establishment of Internet and a lot of web companies, people are getting more and more dependent on the web. #Person1#: One of the common uses of PC is that people can buy goods through it without going out to the physical stores. #Person2#: Can you tell me how it is done? #Person1#: If a cus...</td>\n",
       "      <td>&lt;pad&gt; #Person1# tells #Person2# #Person2# is getting more and more dependent on the web, but she warns #Person2# that people can buy goods through #Person2#'s personal computers because people can order them.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person1#, having the company link to the web, explains what makes the usage of this basic project of a computer system. #Person2# is and instead of taking a day to be home, she buys something online and has a shop in front of her regarding using this service.&lt;/s&gt;</td>\n",
       "      <td>2.067414</td>\n",
       "      <td>2.510709</td>\n",
       "      <td>0.443295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Judy, what is everybody talking about? #Person2#: Haven't you heard? Richard was fired by our manager. #Person1#: You're kidding. It can't be true. #Person2#: Believe it or not. Everybody is talking about it in the company. #Person1#: Really? I'm surprised. #Person2#: Me too. Summary: &lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Judy believes Richard was fired by his manager. Judy is surprised that others are talking about it.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Judy and #Person1# laugh at the fact that Richard's been fired by our manager.&lt;/s&gt;</td>\n",
       "      <td>1.162399</td>\n",
       "      <td>1.567234</td>\n",
       "      <td>0.404836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Mom, I just finished my paper. Can you proofread it before I hand it in? #Person2#: Sure, let's take a look. Sweetie, this is terrific. Your ideas are so original. #Person1#: Thanks. #Person2#: I can tell you worked hard on it. #Person1#: I really did! I started thinking about what I wanted to say three weeks ago. #Person2#: Well, it was definitely worth all the time. #Person1#: Let's just hope my teacher agrees. Summary: &lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person1# wants to send it in to #Person2# when it's ready for let. Abby person insisted that #Person1#, who started working hard on the paper three weeks ago, is worth all the time.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Tom's new paper was applauded. Dad praised #Person1#'s execs's thought. #Person1# after she resided with the paper. Mom agreed to thank her.&lt;/s&gt;</td>\n",
       "      <td>2.109098</td>\n",
       "      <td>2.499128</td>\n",
       "      <td>0.390030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Could you help me figure out how to look for a job? #Person2#: We have lots of options, what type of job do you need? #Person1#: I want to work in an office. #Person2#: Do you want to work part-time or full-time? #Person1#: I want to work full-time. #Person2#: We have binders with local job listings or you can make use of the computers. OK? #Person1#: I am confused a bit but I am sure that I can figure it out. #Person2#: If you make an appoint...</td>\n",
       "      <td>&lt;pad&gt; #Person2# is helping #Person1# find a job in an office. #Person1# wants to work in an office full-time but thinks that #Person1# can get knowledge if #Person1# becomes a counselor for her.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person1# asks #Person2# to help #Person1# find a job in an office. #Person2# encourages #Person1# to have a conversation with a recruiter, and in turn, shares the information it has to offer to #Person1#.&lt;/s&gt;</td>\n",
       "      <td>2.076322</td>\n",
       "      <td>2.271724</td>\n",
       "      <td>0.195402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Summarize the following conversation. #Person1#: What can I do for you, madam? #Person2#: I'd like to buy a toy car for my son. #Person1#: How about this one? #Person2#: It looks nice. How much is it? #Person1#: They're three hundred dollars. #Person2#: Oh, I'm afraid it's too expensive. Can you show me something cheaper? #Person1#: OK, This one is one hundred and twenty. It's the cheapest here. #Person2#: OK, I'll take it. Here's the money. #Person1#: Thank you very much. Summary: &lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person2# is buying a toy car for #Person2#'s son. #Person1# shows #Person2# the cheapest car. #Person2# takes it.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person1# and #Person1# are selling a toy car to #Person2# for a friend's son. #Person2# will take the money.&lt;/s&gt;</td>\n",
       "      <td>1.245610</td>\n",
       "      <td>1.356879</td>\n",
       "      <td>0.111269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Let's take a coffee break, shall we? #Person2#: I wish I could, but I can't. #Person1#: What keeps you so busy? You've been sitting there for hours. You've got to walk around. You just can't stay on the computer forever. #Person2#: Well, I am up to my neck in work. I've got to finish this report. Sarah needs it by noon. I don't want to be scolded if I can't finish my work by the deadline. #Person1#: I understand that, but you'd feel better if ...</td>\n",
       "      <td>&lt;pad&gt; #Person2# cannot take a coffee break because #Person2# is busy with work. #Person1# thinks #Person2# needs a break even for just a few minutes.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person1# and #Person2# desire a coffee break but can't because #Person2#'s busy and keep busy. #Person3# urges #Person2 #Person2# to take a \"break\" even for a short break, so #Person2# can finish a report in time.&lt;/s&gt;</td>\n",
       "      <td>1.794953</td>\n",
       "      <td>1.871372</td>\n",
       "      <td>0.076419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Oh, my God! What's this? #Person2#: What? #Person1#: Look! This window is open. #Person2#: Did you open it before we left? #Person1#: Are you kidding? It's winter. Why would I open it? #Person2#: I don't know. Wait. Is this yours? #Person1#: No! Oh, my God! Someone has broken into the house. #Person2#: It looks that way. That's probably why the door wasn't locked when we came in. #Person1#: I locked it when I left though. #Person2#: Yes, but t...</td>\n",
       "      <td>&lt;pad&gt; Allen interrupts #Person1#'s conversation about the robber who broke into the house. He has noticed the windows are open and he learns the burglar stole a TV, stereo and TV which was already at the house. Allen wanted to look upstairs there but the burglar broke in. Allen can't believe but he teases of possibilities.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Allen comes to find the leftot is open, the window opens, #Person2# says the robber broke into the house and left through the stacer. #Person1# thinking someone could come with them.&lt;/s&gt;</td>\n",
       "      <td>1.854759</td>\n",
       "      <td>1.886263</td>\n",
       "      <td>0.031505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Where shall I register, please? #Person2#: Here. Do you have a registration card? #Person1#: Yes. Here you are. #Person2#: Please register your information here and pay for it. And I'll make a medical record for you. #Person1#: OK. How much do I need to pay for the registration? #Person2#: Please pay ten yuan for the registration. #Person1#: Here is my money. #Person2#: This is your registration card. Please don't lose it and bring it whenever...</td>\n",
       "      <td>&lt;pad&gt; #Person2# asks #Person1# for the registration letter. #Person1# asks #Person2# why the register is so hard, but #Person2# wants to see how to get there.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person2# brings ten yuan for the registration of #Person1# and shares the registration card. #Person2# informs #Person1# ten to come to the pharma.&lt;/s&gt;</td>\n",
       "      <td>1.544993</td>\n",
       "      <td>1.556670</td>\n",
       "      <td>0.011677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Summarize the following conversation. #Person1#: I would like to order some internet today. #Person2#: What kind would you like? #Person1#: What kind of internet is there? #Person2#: You can get DEL or dial-up. #Person1#: Which of those two is best? #Person2#: I would recommend DEL. #Person1#: So that one better? #Person2#: It's better because it doesn't tie up the phone. #Person1#: What do you mean by that? #Person2#: DEL isn't connected through your phone line, but dial-up is. #Person1#: S...</td>\n",
       "      <td>&lt;pad&gt; #Person1# orders some DEL or dial-up internet and learns DEL doesn't tie up the phone.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person2# recommends DEL, #Person1# would like to order DEL, because DEL lines make the phone stump so two phones require DEL.&lt;/s&gt;</td>\n",
       "      <td>2.358537</td>\n",
       "      <td>2.301311</td>\n",
       "      <td>-0.057226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Summarize the following conversation. #Person1#: It smells like an ashtray in here! #Person2#: Hi honey! What's wrong? Why do you have that look on your face? #Person1#: What's wrong? I thought we agreed that you were gonna quit smoking. #Person2#: No! I said I was going to cut down which is very different. You can't just expect me to go cold turkey overnight! #Person1#: Look, there are other ways to quit. You can try the nicotine patch, or nicotine chewing gum. We spend a fortune on cigaret...</td>\n",
       "      <td>&lt;pad&gt; #Person1# tells #Person2# that the smells creep like an ashtray and isn't sure that she takes my method to quit smoking or that she suddenly has a look like an ashtray. #Person1# suggests using the nicotine patch or nicotine chewing gum because they are different.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Hén sees an appearance of an ashtray to trying to quit, but she's very happy about the difference in how to quit.&lt;/s&gt;</td>\n",
       "      <td>1.369807</td>\n",
       "      <td>1.311916</td>\n",
       "      <td>-0.057891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Summarize the following conversation. #Person1#: How much are you asking for this? #Person2#: I'm offering them to you at 150 yuan a piece. Is that all right? #Person1#: Is tax already included in their price? #Person2#: Yes. Our price can't be matched. #Person1#: Would you consider a volume discount? #Person2#: If you buy 1, 000 or more, you'll get a 10 % discount. #Person1#: I'll accept your offer. Summary: &lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person1# wants to pay 150 yuan for 100 handbags for 150 yuan. #Person2# proposes a volume discount of 10% if #Person1# buys more than 1,000.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person2# offers to #Person1# 150 yuan. #Person1# accepts for the supplement price and 10% discount if they buy more.&lt;/s&gt;</td>\n",
       "      <td>2.341830</td>\n",
       "      <td>2.278240</td>\n",
       "      <td>-0.063591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Here is the final draft of our contract. I'm glad that we have reached an agreement on almost every term in our trade. #Person2#: Yes, it seems to me we have come quite a long way. However, let me take a close look at the final draft. #Person1#: Do you have some points to bring up? #Person2#: Well, everything we've discussed seems to be here. #Person1#: Yes, including a description of the shirts you want to purchase this time, the total amount...</td>\n",
       "      <td>&lt;pad&gt; #Person2# shows #Person1# the final draft of the contract and they discuss the revisions in the set of lines. #Person2# provides a couple of details and he will check past notes on everything there and sign the contract now.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person1# says #Person2# has got a contract agreement for almost every terms in their plot. #Person1# gets an excercise of position and titre specs on each detail. #Person2# submitted the final draft following the pointers in #Person2#'s note.&lt;/s&gt;</td>\n",
       "      <td>3.222098</td>\n",
       "      <td>3.088522</td>\n",
       "      <td>-0.133576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Could you help me, Sir? My flight got in 15 minutes ago. Everyone else has picked up the luggage but mine hasn't come through. #Person2#: I'm sorry, Madam, I'll go and find out if there is any more to come. Summary: &lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person1# demands anyone can help #Person1#, even if it is’s #Person1#'s flight. #Person1# asked space enough to collect the luggage to go. Then, #Person2# rocks, and will just find out if there isn't any more.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #2 apologizes and will go to look for someone to take hers but her flight OKed.&lt;/s&gt;</td>\n",
       "      <td>2.172629</td>\n",
       "      <td>2.029722</td>\n",
       "      <td>-0.142907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Hello. I want to reconfirm our flight to London. #Person2#: Yes, sir. Did you call the airline? #Person1#: Yes, I did. But I couldn't communicate with them in English. They speak only Spanish. So I need your help. #Person2#: Certainly, sir. What is the flight number and when are you leaving? #Person1#: We are taking IB 385 to London tomorrow at 1 p. m. #Person2#: Oh, I see, sir. We have the airline office inside the hotel. They have an English...</td>\n",
       "      <td>&lt;pad&gt; #Person1# wants to reconfigure the flight to London. #Person2# will tell #Person1# how to contact the airline and tells him their flight number and when they are leaving. They get a free line from the airline office inside the hotel.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person2# asks #Person1# about their flight to London to England. #Person1# gives the information about flight three and sets the departure time, and #Person1# tells the conversation.&lt;/s&gt;</td>\n",
       "      <td>1.914828</td>\n",
       "      <td>1.753104</td>\n",
       "      <td>-0.161723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Summarize the following conversation. #Person1#: I'd like to have this cashed, please. #Person2#: Please put you name and address here. May I see your passport? #Person1#: Yes. #Person2#: How would you like it? #Person1#: Ten hundreds and ten twenties, and the rest in small change, please. #Person2#: OK. Here you are. Summary: &lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person1# wants to carry an $10 as a private cash with the receipts telling #Person2# it's taxes and change and dates that is important.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person1# offers to buy pirates' stay in small change through #Person2#'s logistics team.&lt;/s&gt;</td>\n",
       "      <td>2.164822</td>\n",
       "      <td>1.882760</td>\n",
       "      <td>-0.282062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Hello? #Person2#: Hello? #Person1#: Can I speak to Li Hong, please? #Person2#: Speaking. #Person1#: Hi, Li Hong. This is Alice. #Person2#: Hi, Alice. How are you? #Person1#: Not bad. Li Hong, I am sorry that I can't go to see Mrs. Brown with you tomorrow morning. My mother is ill. I must take care of her. #Person2#: I'm sorry to hear that. You'd better stay at home. After all, we can visit Mrs. Brown later #Person1#: OK. Bye - bye. #Person2#: ...</td>\n",
       "      <td>&lt;pad&gt; Li Hong wants to see Alice tomorrow morning because Alice's mom is ill. They forget to see Mrs. Brown. Li Hong thinks Li Hong shouldn't stay at home.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Alice annos her mom from she won't go to visit her mother because of her too. So Alice will stay at home.&lt;/s&gt;</td>\n",
       "      <td>1.185997</td>\n",
       "      <td>0.895210</td>\n",
       "      <td>-0.290786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Summarize the following conversation. #Person1#: So how did you like the restaurant? #Person2#: Actually, it could have been better. #Person1#: What didn't you like about it? #Person2#: It is a new restaurant. I don't think they have their act together yet. #Person1#: What did you think about the food? #Person2#: I felt that the food was pretty mediocre. #Person1#: The service wasn't that great, either. #Person2#: I agree. The service was not good. #Person1#: Do you think that you want to tr...</td>\n",
       "      <td>&lt;pad&gt; #Person2# tells #Person1# the trouble of restaurant, the food, and the service were not that great together. #Person2# starts to work on the restaurant again.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person2# tells #Person1# the restaurant has just been bad. The service is not good and #Person2# thinks it's too much for the dinners for the club. 2nd year has been worse. #Person1# wants to go there again.&lt;/s&gt;</td>\n",
       "      <td>2.356818</td>\n",
       "      <td>1.930546</td>\n",
       "      <td>-0.426272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Amanda, how do you like this peaked cap? #Person2#: Didn't you say you want to buy a top hat? #Person1#: But I think this one fits me Well. Why don't you try on the sombrero in black? #Person2#: I don't like caps at all. Summary: &lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Amanda is talking about her buy a peaked cap but #Person2# doesn't like caps.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; Amanda doesn't like a cap at all. Amanda tells #Person1# Amanda just ordered a sombrero. Amanda agrees.&lt;/s&gt;</td>\n",
       "      <td>1.420398</td>\n",
       "      <td>0.990035</td>\n",
       "      <td>-0.430363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Excuse me, could you tell me how to get to the Cross Bakery building? #Person2#: The Cross Bakery building? Oh sure. You're actually walking in the opposite direction. #Person1#: Oh, you're kidding! I thought I was heading east. #Person2#: No, east is the other direction. To get to the Bakery, you need to turn around and go three blocks to Broadway. When you get to the intersection of Broadway and Elm, you hang a left. Go straight down that st...</td>\n",
       "      <td>&lt;pad&gt; #Person1# wants to figure out how to get to the Cross Bakery building. #Person2# starts with walking west after turning three blocks to Broadway, and explains the other directions. #409.16 offers to show #Person1# the way of Cross Bakery which cost $54. #Person1# decided to try it idea. #Person1# agrees and then #Person2# offers #Person1# to find it.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; #Person1# asks #Person2# where to get to the Bakery by walking switched off from #1 to #Person's side. #Person2# points out that #Person1# can't find #Person1# in the West until #M1# solves the grammar. #Person2# offers to show #Person1# the way.&lt;/s&gt;</td>\n",
       "      <td>2.829430</td>\n",
       "      <td>2.367140</td>\n",
       "      <td>-0.462290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Summarize the following conversation. #Person1#: I'm forming a music band. #Person2#: Do you already know how to play an instrument? #Person1#: Uh... Yeah! I'Ve told you a thousand times that I'm learning to play the drums. Now that I know how to play well, I would like to form a rock band. #Person2#: Aside from yourself, who are the other members of the band? #Person1#: We have a guy who plays guitar, and another who plays bass. Although we still haven't found anyone to be our singer. You t...</td>\n",
       "      <td>&lt;pad&gt; #Person1# is forming a rock band with a different station and a guy who plays guitar and another who plays bass. They have to have the other parts for the band so they can audition now. They share their musical talent with couple.&lt;/s&gt;</td>\n",
       "      <td>&lt;pad&gt; A music band will form at their house, and the general director invites #Person1# to audition. This happens every engagement of the band for at least seven episodes and snacks with the band. #Person1# suggests hearing players or then royal whomshe drums. #Person1# invites #Person2#'s cell phone if need be. The music venue is Beijing.&lt;/s&gt;</td>\n",
       "      <td>2.995324</td>\n",
       "      <td>2.485027</td>\n",
       "      <td>-0.510297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  query  \\\n",
       "0   Summarize the following conversation. #Person1#: Today more and more families have personal computers. People have wider range of choice to communicate with the outside world. #Person2#: Right. With the establishment of Internet and a lot of web companies, people are getting more and more dependent on the web. #Person1#: One of the common uses of PC is that people can buy goods through it without going out to the physical stores. #Person2#: Can you tell me how it is done? #Person1#: If a cus...   \n",
       "1                                                                                                                                                                   Summarize the following conversation. #Person1#: Judy, what is everybody talking about? #Person2#: Haven't you heard? Richard was fired by our manager. #Person1#: You're kidding. It can't be true. #Person2#: Believe it or not. Everybody is talking about it in the company. #Person1#: Really? I'm surprised. #Person2#: Me too. Summary: </s>   \n",
       "2                       Summarize the following conversation. #Person1#: Mom, I just finished my paper. Can you proofread it before I hand it in? #Person2#: Sure, let's take a look. Sweetie, this is terrific. Your ideas are so original. #Person1#: Thanks. #Person2#: I can tell you worked hard on it. #Person1#: I really did! I started thinking about what I wanted to say three weeks ago. #Person2#: Well, it was definitely worth all the time. #Person1#: Let's just hope my teacher agrees. Summary: </s>   \n",
       "3   Summarize the following conversation. #Person1#: Could you help me figure out how to look for a job? #Person2#: We have lots of options, what type of job do you need? #Person1#: I want to work in an office. #Person2#: Do you want to work part-time or full-time? #Person1#: I want to work full-time. #Person2#: We have binders with local job listings or you can make use of the computers. OK? #Person1#: I am confused a bit but I am sure that I can figure it out. #Person2#: If you make an appoint...   \n",
       "4           Summarize the following conversation. #Person1#: What can I do for you, madam? #Person2#: I'd like to buy a toy car for my son. #Person1#: How about this one? #Person2#: It looks nice. How much is it? #Person1#: They're three hundred dollars. #Person2#: Oh, I'm afraid it's too expensive. Can you show me something cheaper? #Person1#: OK, This one is one hundred and twenty. It's the cheapest here. #Person2#: OK, I'll take it. Here's the money. #Person1#: Thank you very much. Summary: </s>   \n",
       "5   Summarize the following conversation. #Person1#: Let's take a coffee break, shall we? #Person2#: I wish I could, but I can't. #Person1#: What keeps you so busy? You've been sitting there for hours. You've got to walk around. You just can't stay on the computer forever. #Person2#: Well, I am up to my neck in work. I've got to finish this report. Sarah needs it by noon. I don't want to be scolded if I can't finish my work by the deadline. #Person1#: I understand that, but you'd feel better if ...   \n",
       "6   Summarize the following conversation. #Person1#: Oh, my God! What's this? #Person2#: What? #Person1#: Look! This window is open. #Person2#: Did you open it before we left? #Person1#: Are you kidding? It's winter. Why would I open it? #Person2#: I don't know. Wait. Is this yours? #Person1#: No! Oh, my God! Someone has broken into the house. #Person2#: It looks that way. That's probably why the door wasn't locked when we came in. #Person1#: I locked it when I left though. #Person2#: Yes, but t...   \n",
       "7   Summarize the following conversation. #Person1#: Where shall I register, please? #Person2#: Here. Do you have a registration card? #Person1#: Yes. Here you are. #Person2#: Please register your information here and pay for it. And I'll make a medical record for you. #Person1#: OK. How much do I need to pay for the registration? #Person2#: Please pay ten yuan for the registration. #Person1#: Here is my money. #Person2#: This is your registration card. Please don't lose it and bring it whenever...   \n",
       "8   Summarize the following conversation. #Person1#: I would like to order some internet today. #Person2#: What kind would you like? #Person1#: What kind of internet is there? #Person2#: You can get DEL or dial-up. #Person1#: Which of those two is best? #Person2#: I would recommend DEL. #Person1#: So that one better? #Person2#: It's better because it doesn't tie up the phone. #Person1#: What do you mean by that? #Person2#: DEL isn't connected through your phone line, but dial-up is. #Person1#: S...   \n",
       "9   Summarize the following conversation. #Person1#: It smells like an ashtray in here! #Person2#: Hi honey! What's wrong? Why do you have that look on your face? #Person1#: What's wrong? I thought we agreed that you were gonna quit smoking. #Person2#: No! I said I was going to cut down which is very different. You can't just expect me to go cold turkey overnight! #Person1#: Look, there are other ways to quit. You can try the nicotine patch, or nicotine chewing gum. We spend a fortune on cigaret...   \n",
       "10                                                                                    Summarize the following conversation. #Person1#: How much are you asking for this? #Person2#: I'm offering them to you at 150 yuan a piece. Is that all right? #Person1#: Is tax already included in their price? #Person2#: Yes. Our price can't be matched. #Person1#: Would you consider a volume discount? #Person2#: If you buy 1, 000 or more, you'll get a 10 % discount. #Person1#: I'll accept your offer. Summary: </s>   \n",
       "11  Summarize the following conversation. #Person1#: Here is the final draft of our contract. I'm glad that we have reached an agreement on almost every term in our trade. #Person2#: Yes, it seems to me we have come quite a long way. However, let me take a close look at the final draft. #Person1#: Do you have some points to bring up? #Person2#: Well, everything we've discussed seems to be here. #Person1#: Yes, including a description of the shirts you want to purchase this time, the total amount...   \n",
       "12                                                                                                                                                                                                                                        Summarize the following conversation. #Person1#: Could you help me, Sir? My flight got in 15 minutes ago. Everyone else has picked up the luggage but mine hasn't come through. #Person2#: I'm sorry, Madam, I'll go and find out if there is any more to come. Summary: </s>   \n",
       "13  Summarize the following conversation. #Person1#: Hello. I want to reconfirm our flight to London. #Person2#: Yes, sir. Did you call the airline? #Person1#: Yes, I did. But I couldn't communicate with them in English. They speak only Spanish. So I need your help. #Person2#: Certainly, sir. What is the flight number and when are you leaving? #Person1#: We are taking IB 385 to London tomorrow at 1 p. m. #Person2#: Oh, I see, sir. We have the airline office inside the hotel. They have an English...   \n",
       "14                                                                                                                                                                        Summarize the following conversation. #Person1#: I'd like to have this cashed, please. #Person2#: Please put you name and address here. May I see your passport? #Person1#: Yes. #Person2#: How would you like it? #Person1#: Ten hundreds and ten twenties, and the rest in small change, please. #Person2#: OK. Here you are. Summary: </s>   \n",
       "15  Summarize the following conversation. #Person1#: Hello? #Person2#: Hello? #Person1#: Can I speak to Li Hong, please? #Person2#: Speaking. #Person1#: Hi, Li Hong. This is Alice. #Person2#: Hi, Alice. How are you? #Person1#: Not bad. Li Hong, I am sorry that I can't go to see Mrs. Brown with you tomorrow morning. My mother is ill. I must take care of her. #Person2#: I'm sorry to hear that. You'd better stay at home. After all, we can visit Mrs. Brown later #Person1#: OK. Bye - bye. #Person2#: ...   \n",
       "16  Summarize the following conversation. #Person1#: So how did you like the restaurant? #Person2#: Actually, it could have been better. #Person1#: What didn't you like about it? #Person2#: It is a new restaurant. I don't think they have their act together yet. #Person1#: What did you think about the food? #Person2#: I felt that the food was pretty mediocre. #Person1#: The service wasn't that great, either. #Person2#: I agree. The service was not good. #Person1#: Do you think that you want to tr...   \n",
       "17                                                                                                                                                                                                                          Summarize the following conversation. #Person1#: Amanda, how do you like this peaked cap? #Person2#: Didn't you say you want to buy a top hat? #Person1#: But I think this one fits me Well. Why don't you try on the sombrero in black? #Person2#: I don't like caps at all. Summary: </s>   \n",
       "18  Summarize the following conversation. #Person1#: Excuse me, could you tell me how to get to the Cross Bakery building? #Person2#: The Cross Bakery building? Oh sure. You're actually walking in the opposite direction. #Person1#: Oh, you're kidding! I thought I was heading east. #Person2#: No, east is the other direction. To get to the Bakery, you need to turn around and go three blocks to Broadway. When you get to the intersection of Broadway and Elm, you hang a left. Go straight down that st...   \n",
       "19  Summarize the following conversation. #Person1#: I'm forming a music band. #Person2#: Do you already know how to play an instrument? #Person1#: Uh... Yeah! I'Ve told you a thousand times that I'm learning to play the drums. Now that I know how to play well, I would like to form a rock band. #Person2#: Aside from yourself, who are the other members of the band? #Person1#: We have a guy who plays guitar, and another who plays bass. Although we still haven't found anyone to be our singer. You t...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                               response_before  \\\n",
       "0                                                                                                                                                         <pad> #Person1# tells #Person2# #Person2# is getting more and more dependent on the web, but she warns #Person2# that people can buy goods through #Person2#'s personal computers because people can order them.</s>   \n",
       "1                                                                                                                                                                                                                                                                <pad> Judy believes Richard was fired by his manager. Judy is surprised that others are talking about it.</s>   \n",
       "2                                                                                                                                                                             <pad> #Person1# wants to send it in to #Person2# when it's ready for let. Abby person insisted that #Person1#, who started working hard on the paper three weeks ago, is worth all the time.</s>   \n",
       "3                                                                                                                                                                       <pad> #Person2# is helping #Person1# find a job in an office. #Person1# wants to work in an office full-time but thinks that #Person1# can get knowledge if #Person1# becomes a counselor for her.</s>   \n",
       "4                                                                                                                                                                                                                                                 <pad> #Person2# is buying a toy car for #Person2#'s son. #Person1# shows #Person2# the cheapest car. #Person2# takes it.</s>   \n",
       "5                                                                                                                                                                                                                    <pad> #Person2# cannot take a coffee break because #Person2# is busy with work. #Person1# thinks #Person2# needs a break even for just a few minutes.</s>   \n",
       "6                                     <pad> Allen interrupts #Person1#'s conversation about the robber who broke into the house. He has noticed the windows are open and he learns the burglar stole a TV, stereo and TV which was already at the house. Allen wanted to look upstairs there but the burglar broke in. Allen can't believe but he teases of possibilities.</s>   \n",
       "7                                                                                                                                                                                                           <pad> #Person2# asks #Person1# for the registration letter. #Person1# asks #Person2# why the register is so hard, but #Person2# wants to see how to get there.</s>   \n",
       "8                                                                                                                                                                                                                                                                             <pad> #Person1# orders some DEL or dial-up internet and learns DEL doesn't tie up the phone.</s>   \n",
       "9                                                                                           <pad> #Person1# tells #Person2# that the smells creep like an ashtray and isn't sure that she takes my method to quit smoking or that she suddenly has a look like an ashtray. #Person1# suggests using the nicotine patch or nicotine chewing gum because they are different.</s>   \n",
       "10                                                                                                                                                                                                                     <pad> #Person1# wants to pay 150 yuan for 100 handbags for 150 yuan. #Person2# proposes a volume discount of 10% if #Person1# buys more than 1,000.</s>   \n",
       "11                                                                                                                                  <pad> #Person2# shows #Person1# the final draft of the contract and they discuss the revisions in the set of lines. #Person2# provides a couple of details and he will check past notes on everything there and sign the contract now.</s>   \n",
       "12                                                                                                                                                <pad> #Person1# demands anyone can help #Person1#, even if it is’s #Person1#'s flight. #Person1# asked space enough to collect the luggage to go. Then, #Person2# rocks, and will just find out if there isn't any more.</s>   \n",
       "13                                                                                                                         <pad> #Person1# wants to reconfigure the flight to London. #Person2# will tell #Person1# how to contact the airline and tells him their flight number and when they are leaving. They get a free line from the airline office inside the hotel.</s>   \n",
       "14                                                                                                                                                                                                                          <pad> #Person1# wants to carry an $10 as a private cash with the receipts telling #Person2# it's taxes and change and dates that is important.</s>   \n",
       "15                                                                                                                                                                                                             <pad> Li Hong wants to see Alice tomorrow morning because Alice's mom is ill. They forget to see Mrs. Brown. Li Hong thinks Li Hong shouldn't stay at home.</s>   \n",
       "16                                                                                                                                                                                                    <pad> #Person2# tells #Person1# the trouble of restaurant, the food, and the service were not that great together. #Person2# starts to work on the restaurant again.</s>   \n",
       "17                                                                                                                                                                                                                                                                                     <pad> Amanda is talking about her buy a peaked cap but #Person2# doesn't like caps.</s>   \n",
       "18  <pad> #Person1# wants to figure out how to get to the Cross Bakery building. #Person2# starts with walking west after turning three blocks to Broadway, and explains the other directions. #409.16 offers to show #Person1# the way of Cross Bakery which cost $54. #Person1# decided to try it idea. #Person1# agrees and then #Person2# offers #Person1# to find it.</s>   \n",
       "19                                                                                                                            <pad> #Person1# is forming a rock band with a different station and a guy who plays guitar and another who plays bass. They have to have the other parts for the band so they can audition now. They share their musical talent with couple.</s>   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                               response_after  \\\n",
       "0                                                                              <pad> #Person1#, having the company link to the web, explains what makes the usage of this basic project of a computer system. #Person2# is and instead of taking a day to be home, she buys something online and has a shop in front of her regarding using this service.</s>   \n",
       "1                                                                                                                                                                                                                                                                    <pad> Judy and #Person1# laugh at the fact that Richard's been fired by our manager.</s>   \n",
       "2                                                                                                                                                                                                      <pad> Tom's new paper was applauded. Dad praised #Person1#'s execs's thought. #Person1# after she resided with the paper. Mom agreed to thank her.</s>   \n",
       "3                                                                                                                                     <pad> #Person1# asks #Person2# to help #Person1# find a job in an office. #Person2# encourages #Person1# to have a conversation with a recruiter, and in turn, shares the information it has to offer to #Person1#.</s>   \n",
       "4                                                                                                                                                                                                                                     <pad> #Person1# and #Person1# are selling a toy car to #Person2# for a friend's son. #Person2# will take the money.</s>   \n",
       "5                                                                                                                            <pad> #Person1# and #Person2# desire a coffee break but can't because #Person2#'s busy and keep busy. #Person3# urges #Person2 #Person2# to take a \"break\" even for a short break, so #Person2# can finish a report in time.</s>   \n",
       "6                                                                                                                                                            <pad> Allen comes to find the leftot is open, the window opens, #Person2# says the robber broke into the house and left through the stacer. #Person1# thinking someone could come with them.</s>   \n",
       "7                                                                                                                                                                                              <pad> #Person2# brings ten yuan for the registration of #Person1# and shares the registration card. #Person2# informs #Person1# ten to come to the pharma.</s>   \n",
       "8                                                                                                                                                                                                                    <pad> #Person2# recommends DEL, #Person1# would like to order DEL, because DEL lines make the phone stump so two phones require DEL.</s>   \n",
       "9                                                                                                                                                                                                                                 <pad> Hén sees an appearance of an ashtray to trying to quit, but she's very happy about the difference in how to quit.</s>   \n",
       "10                                                                                                                                                                                                                            <pad> #Person2# offers to #Person1# 150 yuan. #Person1# accepts for the supplement price and 10% discount if they buy more.</s>   \n",
       "11                                                                                              <pad> #Person1# says #Person2# has got a contract agreement for almost every terms in their plot. #Person1# gets an excercise of position and titre specs on each detail. #Person2# submitted the final draft following the pointers in #Person2#'s note.</s>   \n",
       "12                                                                                                                                                                                                                                                                  <pad> #2 apologizes and will go to look for someone to take hers but her flight OKed.</s>   \n",
       "13                                                                                                                                                          <pad> #Person2# asks #Person1# about their flight to London to England. #Person1# gives the information about flight three and sets the departure time, and #Person1# tells the conversation.</s>   \n",
       "14                                                                                                                                                                                                                                                        <pad> #Person1# offers to buy pirates' stay in small change through #Person2#'s logistics team.</s>   \n",
       "15                                                                                                                                                                                                                                        <pad> Alice annos her mom from she won't go to visit her mother because of her too. So Alice will stay at home.</s>   \n",
       "16                                                                                                                                 <pad> #Person2# tells #Person1# the restaurant has just been bad. The service is not good and #Person2# thinks it's too much for the dinners for the club. 2nd year has been worse. #Person1# wants to go there again.</s>   \n",
       "17                                                                                                                                                                                                                                          <pad> Amanda doesn't like a cap at all. Amanda tells #Person1# Amanda just ordered a sombrero. Amanda agrees.</s>   \n",
       "18                                                                                           <pad> #Person1# asks #Person2# where to get to the Bakery by walking switched off from #1 to #Person's side. #Person2# points out that #Person1# can't find #Person1# in the West until #M1# solves the grammar. #Person2# offers to show #Person1# the way.</s>   \n",
       "19  <pad> A music band will form at their house, and the general director invites #Person1# to audition. This happens every engagement of the band for at least seven episodes and snacks with the band. #Person1# suggests hearing players or then royal whomshe drums. #Person1# invites #Person2#'s cell phone if need be. The music venue is Beijing.</s>   \n",
       "\n",
       "    reward_before  reward_after  reward_diff  \n",
       "0        2.067414      2.510709     0.443295  \n",
       "1        1.162399      1.567234     0.404836  \n",
       "2        2.109098      2.499128     0.390030  \n",
       "3        2.076322      2.271724     0.195402  \n",
       "4        1.245610      1.356879     0.111269  \n",
       "5        1.794953      1.871372     0.076419  \n",
       "6        1.854759      1.886263     0.031505  \n",
       "7        1.544993      1.556670     0.011677  \n",
       "8        2.358537      2.301311    -0.057226  \n",
       "9        1.369807      1.311916    -0.057891  \n",
       "10       2.341830      2.278240    -0.063591  \n",
       "11       3.222098      3.088522    -0.133576  \n",
       "12       2.172629      2.029722    -0.142907  \n",
       "13       1.914828      1.753104    -0.161723  \n",
       "14       2.164822      1.882760    -0.282062  \n",
       "15       1.185997      0.895210    -0.290786  \n",
       "16       2.356818      1.930546    -0.426272  \n",
       "17       1.420398      0.990035    -0.430363  \n",
       "18       2.829430      2.367140    -0.462290  \n",
       "19       2.995324      2.485027    -0.510297  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 500)\n",
    "df_compare_results = pd.DataFrame(compare_results)\n",
    "df_compare_results[\"reward_diff\"] = df_compare_results['reward_after'] - df_compare_results['reward_before']\n",
    "df_compare_results_sorted = df_compare_results.sort_values(by=['reward_diff'], ascending=False).reset_index(drop=True)\n",
    "df_compare_results_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a89397a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
